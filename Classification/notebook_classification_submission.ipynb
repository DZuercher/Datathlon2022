{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../raw_data/trainset_full.csv\", low_memory=False) #change here tomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we do feature engineering:\n",
    "\n",
    "- Have weeks, months and hour of day as feature and generate metafeatures of them with\n",
    "    - weeks 13,14,5,7,37,29,30,31 are weeks where \"planned\" errors occur: highweek feature\n",
    "    - bimonthpark measures interaction between park and bimonth\n",
    "    -isnight check whether it is night because of noise reduction\n",
    "    -isnoon check whether it is between 7-14 because there unplanned maintenance usually happens\n",
    "    -Error makes the errors binary\n",
    "    -speed and direction average rotor speed and generator speed and nacelle direction and wind direction, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "df[\"measured_at\"]=pd.to_datetime(df.measured_at)\n",
    "df[\"week\"]=np.int64(df.measured_at.dt.isocalendar().week)\n",
    "\n",
    "\n",
    "df[\"isweek14\"]=df.week == 14\n",
    "df[\"isweek13\"] = df.week ==13\n",
    "df[\"isweek5737\"]= (df.week == 5) | (df.week == 7) | (df.week == 37)\n",
    "df[\"isweek293031\"]=(df.week == 29) | (df.week==30) | (df.week == 31)\n",
    "df[\"highweek\"]= (df.week == 14) | (df.week ==13) | (df.week == 5) | (df.week == 7) | (df.week == 37) | (df.week == 29) | (df.week==30) | (df.week == 31)\n",
    "df[\"month\"]=df.measured_at.dt.month\n",
    "df[\"bimonth\"]=df.month// 2 \n",
    "df[\"bimonthpark\"]= str(df.bimonth)+\":\"+str(df.park_id)\n",
    "df[\"hourofday\"]=df.measured_at.dt.hour\n",
    "df[\"isnight\"]=(df.hourofday >= 18) | (df.hourofday <=5)\n",
    "df[\"isnoon\"]=(df.hourofday >= 7) & (df.hourofday<=14)\n",
    "\n",
    "df[\"Error\"]=df.error_category != \"NO_ERROR\"\n",
    "\n",
    "df[\"speed\"]=(df.rotor_speed+df.generator_speed)\n",
    "df[\"direction\"]=(df.nacelle_direction+df.wind_direction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features for XGB below, drop the bimonthpark as XGB can figure out interaction itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_attribs=['turbine_id', 'wind_speed', 'power','week',\n",
    "       'temp_environment', 'temp_hydraulic_oil', 'temp_gear_bearing', 'cosphi',\n",
    "       'blade_angle_avg', 'hydraulic_pressure', 'park_id', 'month', 'speed', 'direction','isnight', 'isnoon','highweek']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ordinal encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "labelencoder.fit(df.error_category)\n",
    "df[\"EncodedErrors\"]=labelencoder.transform(df.error_category)\n",
    "\n",
    "X_train_xgb=df[xgb_attribs]\n",
    "y_train_xgb=df.EncodedErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    1272609\n",
       "0       47724\n",
       "1       21651\n",
       "11      10224\n",
       "14       4893\n",
       "2        3743\n",
       "6        1771\n",
       "9        1494\n",
       "16       1081\n",
       "3         787\n",
       "13        495\n",
       "12        409\n",
       "4         141\n",
       "7         108\n",
       "15         32\n",
       "8          22\n",
       "10          4\n",
       "5           2\n",
       "Name: EncodedErrors, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_xgb.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier with logloss (variant of AdaBoost), hyperparameters trained separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:35:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.0, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0.1, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=7, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=97, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#adjust parameters tomorrow\n",
    "\n",
    "xgb=XGBClassifier(objective=\"multi:softmax\",use_label_encoder=False, n_estimators=97 , learning_rate=0.1, max_depth=7,gamma=0.1, alpha=0.0)\n",
    "xgb.fit(X_train_xgb, y_train_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('xgbclassifier.pickle', 'wb+') as f:\n",
    "            pickle.dump(xgb, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgbclassifier.pickle', 'rb') as f:\n",
    "    xgb_pickle=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_y=xgb_pickle.predict(X_train_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load imputed test data, copy, and create test feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_raw=pd.read_csv(\"../raw_data/testset_full.csv\",low_memory=False) \n",
    "tdf=tdf_raw.copy()\n",
    "\n",
    "tdf[\"measured_at\"]=pd.to_datetime(tdf.measured_at)\n",
    "tdf[\"week\"]=np.int64(tdf.measured_at.dt.isocalendar().week)\n",
    "tdf[\"highweek\"]= (tdf.week == 14) | (tdf.week ==13) | (tdf.week == 5) | (tdf.week == 7) | (tdf.week == 37) | (tdf.week == 29) | (tdf.week==30) | (tdf.week == 31)\n",
    "tdf[\"month\"]=tdf.measured_at.dt.month\n",
    "tdf[\"hourofday\"]=tdf.measured_at.dt.hour\n",
    "tdf[\"isnight\"]=(tdf.hourofday >= 18) | (tdf.hourofday <=5)\n",
    "tdf[\"isnoon\"]=(tdf.hourofday >= 7) & (tdf.hourofday<=14)\n",
    "\n",
    "tdf[\"speed\"]=(tdf.rotor_speed+tdf.generator_speed)\n",
    "tdf[\"direction\"]=(tdf.nacelle_direction+tdf.wind_direction)\n",
    "\n",
    "X_test_xgb=tdf[xgb_attribs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3p/ttgsc6nj4cbcm38kk_kk7wdc00gvp4/T/ipykernel_35250/960673935.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_hat_xgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_hat_xgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0miteration_range\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     ) -> np.ndarray:\n\u001b[0;32m-> 1284\u001b[0;31m         class_probs = super().predict(\n\u001b[0m\u001b[1;32m   1285\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m                 predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m    882\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                     \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2038\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_ensure_np_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_np_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m             _check_call(\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 _LIB.XGBoosterPredictFromDense(\n\u001b[1;32m   2042\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "y_hat_xgb=xgb.predict(X_test_xgb)\n",
    "\n",
    "#Decode\n",
    "y_hat_xgb=labelencoder.inverse_transform(y_hat_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv \n",
    "tdf_raw[\"error_category\"]=y_hat_xgb\n",
    "\n",
    "tdf_raw.to_csv(\"Prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f20724ad43ab919d9c7bc243f4e6f22cc4f6c9eb417b6785f57a74d3e0b71f06"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
